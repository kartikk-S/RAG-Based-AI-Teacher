import requests
import os
import json
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import joblib

def create_embedding(text_list, batch_size):
    all_embeddings=[]
    # https://github.com/ollama/ollama/blob/main/docs/api.md#generate-embeddings
    

    for i in range(0,len(text_list),batch_size):

        batch=text_list[i:i+batch_size]

        r = requests.post("http://localhost:11434/api/embed", json={
        "model": "bge-m3",
        "input": batch
        })

        data=r.json()

        if "embeddings" not in data:
            print("ERROR:", data)
            continue

        all_embeddings.extend(data["embeddings"])

    return all_embeddings


jsons = os.listdir("jsons")  # List all the jsons 
my_dicts = []
chunk_id = 0

for json_file in jsons:
    with open(f"jsons/{json_file}") as f:
        content = json.load(f)
    print(f"Creating Embeddings for {json_file}")
    embeddings = create_embedding([c["text"] for c in content["chunks"]],10)
    print(len(embeddings))
    print(len(content["chunks"]))
    for i, chunk in enumerate(content['chunks']):
        chunk['chunk_id'] = chunk_id
        chunk['embedding'] = embeddings[i]
        chunk_id += 1
        my_dicts.append(chunk)

df = pd.DataFrame.from_records(my_dicts)
print(df)
# a = create_embedding(["Cat sat on the mat", "Harry dances on a mat"])
# print(a)

joblib.dump(df, 'embeddings.joblib')
